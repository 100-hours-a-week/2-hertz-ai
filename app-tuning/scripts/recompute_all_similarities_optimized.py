"""
ìµœì í™”ëœ ìœ ì‚¬ë„ ì¬ê³„ì‚° ìŠ¤í¬ë¦½íŠ¸ (V3)

ì£¼ìš” ê°œì„  ì‚¬í•­:
1. **ë°ì´í„° ì¼ê´„ ë¡œë”©**: ëª¨ë“  ì‚¬ìš©ì ë°ì´í„°ë¥¼ ì²˜ìŒì— í•œ ë²ˆë§Œ ë¡œë“œí•˜ì—¬ DB I/O ìµœì†Œí™”.
2. **ë°ì´í„° ê³µìœ **: ë¡œë“œëœ ë°ì´í„°ë¥¼ ê° ë³‘ë ¬ í”„ë¡œì„¸ìŠ¤ì— ì¸ìë¡œ ì „ë‹¬í•˜ì—¬ ì¤‘ë³µ ë¡œë”© ë°©ì§€.
3. `user_service.py`ì˜ `update_similarity_for_users_v3` í•¨ìˆ˜ë¥¼ ì¬ì‚¬ìš©í•˜ì—¬ ì½”ë“œ ì¼ê´€ì„± ìœ ì§€.
4. `ThreadPoolExecutor`ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ìë³„ 'friend' ë° 'couple' ì¹´í…Œê³ ë¦¬ ê³„ì‚°ì„ ë³‘ë ¬ë¡œ ìˆ˜í–‰.
5. `upsert` ë¡œì§ì„ ê°œì„ í•˜ì—¬ ì‹¤ì œ ë³€ê²½ì´ ìˆì„ ë•Œë§Œ DBì— ì“°ë„ë¡ ìµœì í™”.
6. ë¶ˆí•„ìš”í•œ ë¡œê·¸ ì œê±° ë° ì„±ëŠ¥ ì¸¡ì • ë¡œê·¸ ì •ë¦¬.
"""

import concurrent.futures
import os
import sys
import time
import traceback

import numpy as np

script_dir = os.path.dirname(__file__)
project_root = os.path.abspath(os.path.join(script_dir, os.pardir))
sys.path.insert(0, project_root)

from core.vector_database import get_user_collection  # noqa: E402
from services.user_service import update_similarity_for_users_v3  # noqa: E402
from utils.logger import log_performance, logger  # noqa: E402

# ìµœì í™”ëœ ì›Œì»¤ ìˆ˜ (CPU ì½”ì–´ì˜ 75% ì‚¬ìš©)
# WORKER_COUNT = max(1, int(os.cpu_count() * 0.75))
BATCH_SIZE = 10  # ë¡œê·¸ ì¶œë ¥ ë‹¨ìœ„


def get_all_users_data():
    """ëª¨ë“  ì‚¬ìš©ì ë°ì´í„°ë¥¼ í•œ ë²ˆì— ê°€ì ¸ì˜µë‹ˆë‹¤."""
    try:
        logger.info("ğŸ“Š ëª¨ë“  ì‚¬ìš©ì ë°ì´í„° ë¡œë”© ì¤‘...")
        data = get_user_collection().get(include=["embeddings", "metadatas"])
        logger.info(f"âœ… {len(data['ids'])}ëª…ì˜ ì‚¬ìš©ì ë°ì´í„° ë¡œë”© ì™„ë£Œ")
        return data
    except Exception as e:
        logger.error(f"[CRITICAL] ì‚¬ìš©ì ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}")
        return None


def convert_numpy_floats(obj):
    if isinstance(obj, np.float32):
        return float(obj)
    if isinstance(obj, dict):
        return {k: convert_numpy_floats(v) for k, v in obj.items()}
    if isinstance(obj, list):
        return [convert_numpy_floats(i) for i in obj]
    return obj


def process_user_category(user_id: str, category: str, all_users_data: dict):
    """ë‹¨ì¼ ì‚¬ìš©ìì˜ íŠ¹ì • ì¹´í…Œê³ ë¦¬ ìœ ì‚¬ë„ë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤."""
    try:
        # update_similarity_for_users_v3 ë‚´ë¶€ì—ì„œ similaritiesë¥¼ ì €ì¥í•˜ê¸° ì „ì— float32 ë³€í™˜ì´ ëˆ„ë½ë  ìˆ˜ ìˆìœ¼ë¯€ë¡œ,
        # ë³€í™˜ì„ ê°•ì œ ì ìš© (í•¨ìˆ˜ ë‚´ë¶€ì—ì„œ ì´ë¯¸ ì²˜ë¦¬ ì¤‘ì´ì–´ë„ ì¤‘ë³µ ì ìš©ì€ ë¬´í•´)
        update_similarity_for_users_v3(user_id, category, all_users_data)
        return True, None
    except Exception as e:
        error_message = f"[ERROR] {category} ìœ ì‚¬ë„ ê³„ì‚° ì‹¤íŒ¨ for {user_id}: {e}"
        return False, error_message


def process_user_wrapper(user_id: str, all_users_data: dict):
    """
    í•œ ëª…ì˜ ì‚¬ìš©ìì— ëŒ€í•´ 'friend'ì™€ 'couple' ì¹´í…Œê³ ë¦¬ ìœ ì‚¬ë„ ê³„ì‚°ì„
    ë³‘ë ¬ë¡œ ì²˜ë¦¬í•˜ëŠ” ë˜í¼ í•¨ìˆ˜ì…ë‹ˆë‹¤.
    """
    categories = ["friend", "couple"]
    success_count = 0
    errors = []

    with concurrent.futures.ThreadPoolExecutor(max_workers=len(categories)) as executor:
        future_to_category = {
            executor.submit(
                process_user_category, user_id, category, all_users_data
            ): category
            for category in categories
        }

        for future in concurrent.futures.as_completed(future_to_category):
            success, error = future.result()
            if success:
                success_count += 1
            else:
                errors.append(error)

    if success_count == len(categories):
        return True, user_id
    else:
        logger.error(f"âŒ {user_id} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {errors}")
        return False, user_id


# @log_performance(
#     operation_name="recompute_all_similarities_optimized", include_memory=True
# )
# def recompute_all_similarities_optimized():
#     """ìµœì í™”ëœ ìœ ì‚¬ë„ ì¬ê³„ì‚° ë©”ì¸ í•¨ìˆ˜"""
#     logger.info("ğŸš€ ìµœì í™”ëœ ìœ ì‚¬ë„ ì¬ê³„ì‚° ì‹œì‘ (V3)...")
#     start_time = time.time()

#     all_users_data = get_all_users_data()
#     if not all_users_data or not all_users_data.get("ids"):
#         logger.warning("ì²˜ë¦¬í•  ì‚¬ìš©ìê°€ ì—†ìŠµë‹ˆë‹¤.")
#         return

#     user_ids = all_users_data["ids"]
#     total_users = len(user_ids)
#     logger.info(f"ğŸ“ˆ ì²˜ë¦¬ ëŒ€ìƒ ì‚¬ìš©ì: {total_users}ëª…")
#     # logger.info(f"âš™ï¸ ì›Œì»¤ ìˆ˜: {WORKER_COUNT}")

#     processed_count = 0
#     success_count = 0
#     failure_count = 0

#     with concurrent.futures.ThreadPoolExecutor(max_workers=WORKER_COUNT) as executor:
#         future_to_user_id = {
#             executor.submit(process_user_wrapper, user_id, all_users_data): user_id
#             for user_id in user_ids
#         }

#         for future in concurrent.futures.as_completed(future_to_user_id):
#             processed_count += 1
#             try:
#                 success, user_id = future.result()
#                 if success:
#                     success_count += 1
#                 else:
#                     failure_count += 1

#                 if processed_count % BATCH_SIZE == 0 or processed_count == total_users:
#                     progress = (processed_count / total_users) * 100
#                     logger.info(
#                         f"ğŸ”„ ì§„í–‰ë¥ : {processed_count}/{total_users} ({progress:.1f}%) "
#                         f"(ì„±ê³µ: {success_count}, ì‹¤íŒ¨: {failure_count})"
#                     )

#             except Exception as e:
#                 user_id = future_to_user_id[future]
#                 logger.error(
#                     f"[CRITICAL] ì‚¬ìš©ì {user_id} ì²˜ë¦¬ ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜ ë°œìƒ: {e}"
#                 )
#                 traceback.print_exc()
#                 failure_count += 1

#     total_time = time.time() - start_time
#     logger.info("ğŸ‰ ì „ì²´ ìœ ì‚¬ë„ ì¬ê³„ì‚° ì™„ë£Œ!")
#     logger.info(f"ğŸ“Š ì´ ì²˜ë¦¬ ì‹œê°„: {total_time:.2f}ì´ˆ")
#     logger.info(f"âœ… ì„±ê³µ: {success_count}, âŒ ì‹¤íŒ¨: {failure_count}")
#     if total_time > 0:
#         logger.info(f"âš¡ï¸ í‰ê·  ì²˜ë¦¬ ì†ë„: {total_users / total_time:.2f} users/sec")


@log_performance(
    operation_name="recompute_all_similarities_optimized_v2", include_memory=True
)
def recompute_all_similarities_optimized_v2():
    """ìˆœì°¨ ì²˜ë¦¬ ë°©ì‹ìœ¼ë¡œ ë³€ê²½ëœ ìœ ì‚¬ë„ ì¬ê³„ì‚° ë©”ì¸ í•¨ìˆ˜"""
    logger.info("ğŸŒ ìˆœì°¨ ì²˜ë¦¬ ë°©ì‹ì˜ ìœ ì‚¬ë„ ì¬ê³„ì‚° ì‹œì‘ (V3)...")
    start_time = time.time()

    all_users_data = get_all_users_data()
    if not all_users_data or not all_users_data.get("ids"):
        logger.warning("ì²˜ë¦¬í•  ì‚¬ìš©ìê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    user_ids = all_users_data["ids"]
    total_users = len(user_ids)
    logger.info(f"ğŸ“ˆ ì²˜ë¦¬ ëŒ€ìƒ ì‚¬ìš©ì: {total_users}ëª…")

    processed_count = 0
    success_count = 0
    failure_count = 0

    # --- ê¸°ì¡´ ë³‘ë ¬ ì²˜ë¦¬ ì½”ë“œ ---
    # with concurrent.futures.ThreadPoolExecutor(max_workers=WORKER_COUNT) as executor:
    #     future_to_user_id = { ... }
    #     for future in concurrent.futures.as_completed(future_to_user_id):
    #         ...

    # --- âœ¨ ë³€ê²½ëœ ìˆœì°¨ ì²˜ë¦¬ ì½”ë“œ ---
    for user_id in user_ids:
        processed_count += 1
        try:
            # ê° ì‚¬ìš©ìë¥¼ ìˆœì„œëŒ€ë¡œ í•˜ë‚˜ì”© ì²˜ë¦¬
            success, _ = process_user_wrapper(user_id, all_users_data)
            if success:
                success_count += 1
            else:
                failure_count += 1

        except Exception as e:
            logger.error(f"[CRITICAL] ì‚¬ìš©ì {user_id} ì²˜ë¦¬ ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
            traceback.print_exc()
            failure_count += 1

        # ì§„í–‰ë¥  ë¡œê¹… (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
        if processed_count % BATCH_SIZE == 0 or processed_count == total_users:
            progress = (processed_count / total_users) * 100
            logger.info(
                f"ğŸ”„ ì§„í–‰ë¥ : {processed_count}/{total_users} ({progress:.1f}%) "
                f"(ì„±ê³µ: {success_count}, ì‹¤íŒ¨: {failure_count})"
            )

    total_time = time.time() - start_time
    logger.info("ğŸ‰ ì „ì²´ ìœ ì‚¬ë„ ì¬ê³„ì‚° ì™„ë£Œ!")
    logger.info(f"ğŸ“Š ì´ ì²˜ë¦¬ ì‹œê°„: {total_time:.2f}ì´ˆ")
    logger.info(f"âœ… ì„±ê³µ: {success_count}, âŒ ì‹¤íŒ¨: {failure_count}")
    if total_time > 0:
        logger.info(f"âš¡ï¸ í‰ê·  ì²˜ë¦¬ ì†ë„: {total_users / total_time:.2f} users/sec")


if __name__ == "__main__":
    recompute_all_similarities_optimized_v2()
