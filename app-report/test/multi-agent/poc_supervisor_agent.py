import time

import GPUtil
from langchain_openai import ChatOpenAI
from langgraph.prebuilt import create_react_agent
from langgraph_supervisor import create_supervisor


def get_vram_usage():
    gpus = GPUtil.getGPUs()
    if gpus:
        return gpus[0].memoryUsed  # MB ë‹¨ìœ„
    return 0


# ëª¨ë“ˆ ì„í¬íŠ¸ ì‹œì ì— ë°”ë¡œ ëª¨ë¸ ì´ˆê¸°í™”
# @log_performance(operation_name="load_vllm_model", include_memory=True)
def _load_model():
    """
    VLLM Qwen2-7B-Instruct ëª¨ë¸ì„ ë¡œë”©í•©ë‹ˆë‹¤.
    """

    try:
        # logger.info(" VLLM[Qwen2-7B-Instruct] ëª¨ë¸ ë¡œë”© ì‹œì‘...")

        start_time = time.time()
        gpu_mem_before = get_vram_usage()
        # ëª¨ë¸ ë¡œë“œ
        inference_server_url = "http://localhost:8001/v1"
        loaded_model = ChatOpenAI(
            model="Qwen/Qwen2.5-7B-Instruct-AWQ",
            openai_api_key="EMPTY",
            openai_api_base=inference_server_url,
        )
        # ëª¨ë¸ ì˜ˆì—´ (ì²« ì¶”ë¡  ì‹œê°„ ë‹¨ì¶•)
        # _ = loaded_model.invoke("ëª¨ë¸ ì˜ˆì—´ìš© í…ìŠ¤íŠ¸", max_token=50, temperature=0.91)

        elapsed = round(time.time() - start_time, 2)
        gpu_mem_after = get_vram_usage()
        gpu_diff = gpu_mem_after - gpu_mem_before

        # logger.info(
        #     f" VLLM ëª¨ë¸ ë¡œë”© ì™„ë£Œ: {elapsed}s | GPU ì‚¬ìš©ëŸ‰: {gpu_mem_after:.2f}MB (+{gpu_diff:.2f}MB)"
        # )
        return loaded_model

    except Exception as e:
        # logger.exception(f" ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
        raise


# ëª¨ë“ˆ ë ˆë²¨ì—ì„œ ëª¨ë¸ ì´ˆê¸°í™”
model = _load_model()


# ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ì— ì ‘ê·¼í•˜ê¸° ìœ„í•œ ê°„ë‹¨í•œ í•¨ìˆ˜
def get_model():
    """
    ì´ˆê¸°í™”ëœ Qwen ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜

    Returns:
        Qwen: ì´ˆê¸°í™”ëœ Qwen ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤
    """
    return model


def book_hotel(hotel_name: str):
    """Book a hotel"""
    return f"Successfully booked a stay at {hotel_name}."


def book_flight(from_airport: str, to_airport: str):
    """Book a flight"""
    return f"Successfully booked a flight from {from_airport} to {to_airport}."


model = get_model()

flight_assistant = create_react_agent(
    model=model,
    tools=[book_flight],
    prompt="You are a flight booking assistant. When you receive flight booking requests, immediately book the flight using the book_flight tool with the provided information. Do not ask for confirmation - just execute the booking.",
    name="flight_assistant",
)

hotel_assistant = create_react_agent(
    model=model,
    tools=[book_hotel],
    prompt="You are a hotel booking assistant",
    name="hotel_assistant",
)

# model : Qwen/Qwen2.5-7B-Instruct-AWQ
supervisor = create_supervisor(
    agents=[flight_assistant, hotel_assistant],
    model=model,
    prompt=(
        "You manage a hotel booking assistant and a"
        "flight booking assistant. Assign work to them."
    ),
).compile()

for chunk in supervisor.stream(
    {
        "messages": [
            {
                "role": "user",
                "content": "book a flight from BOS to JFK on January 15th and a stay at McKittrick Hotel from January 15th to January 18th",
            }
        ]
    }
):
    print(chunk)
    print("\n")

input_data = {
    "messages": [
        {
            "role": "user",
            "content": "book a flight from BOS to JFK on January 15th and a stay at McKittrick Hotel from January 15th to January 18th",
        }
    ]
}


def extract_final_supervisor_response(supervisor, input_data):
    """ë§ˆì§€ë§‰ supervisor ì‘ë‹µë§Œ ì¶”ì¶œí•˜ì—¬ ì¶œë ¥"""
    all_chunks = []

    # ëª¨ë“  chunkë¥¼ ìˆ˜ì§‘
    for chunk in supervisor.stream(input_data):
        if chunk:
            all_chunks.append(chunk)

    # ë§ˆì§€ë§‰ supervisor ì‘ë‹µ ì°¾ê¸°
    for chunk in reversed(all_chunks):
        if "supervisor" in chunk and chunk["supervisor"]:
            if "messages" in chunk["supervisor"]:
                messages = chunk["supervisor"]["messages"]
                # ë§ˆì§€ë§‰ AI ë©”ì‹œì§€ ì°¾ê¸°
                for message in reversed(messages):
                    if hasattr(message, "content") and hasattr(message, "name"):
                        if message.name == "supervisor" and message.content.strip():
                            print("ğŸ¯ ìµœì¢… ì˜ˆì•½ ê²°ê³¼:")
                            print("=" * 50)
                            print(message.content)
                            print("=" * 50)

    print("âŒ Supervisorì˜ ìµœì¢… ì‘ë‹µì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")


extract_final_supervisor_response(supervisor, input_data)
