import asyncio
import json
import operator
import os
import re
from typing import Annotated, Sequence, TypedDict

from langchain import hub
from langchain.agents import AgentExecutor, create_structured_chat_agent

# from langgraph.prebuilt import create_react_agent
# from langgraph_supervisor import create_supervisor
from langchain_core.messages import AIMessage, BaseMessage, HumanMessage
from langchain_mcp_adapters.client import MultiServerMCPClient
from langgraph.graph import END, START, StateGraph

from ...models import qwen_loader_gcp_vllm
from ...utils.logger import logger


def safe_json_parse(text: str) -> dict:
    """JSON ë¬¸ìì—´ì—ì„œ ì½”ë“œ ë¸”ë¡ê³¼ ì„¤ëª…ì„ ì œê±°í•˜ê³  ì•ˆì „í•˜ê²Œ íŒŒì‹±í•©ë‹ˆë‹¤."""
    # ```json ... ``` íŒ¨í„´ì„ ì°¾ì•„ ë‚´ìš©ë§Œ ì¶”ì¶œ
    match = re.search(r"```json\s*([\s\S]+?)\s*```", text)
    if match:
        text = match.group(1)

    # ê°„í˜¹ ì‘ë‹µì´ {..} í˜•íƒœê°€ ì•„ë‹Œ ê²½ìš°ê°€ ìˆì–´ ì¶”ê°€ ë³´ì •
    text = text.strip()
    if not text.startswith("{"):
        text = "{" + text
    if not text.endswith("}"):
        text = text + "}"

    try:
        return json.loads(text)
    except json.JSONDecodeError as e:
        logger.error(f"JSON íŒŒì‹± ì‹¤íŒ¨: {e}\nì›ë³¸ í…ìŠ¤íŠ¸: {text}")
        return {}  # ì‹¤íŒ¨ ì‹œ ë¹ˆ ë”•ì…”ë„ˆë¦¬ ë°˜í™˜


def load_mcp_config():
    """í˜„ì¬ ë””ë ‰í† ë¦¬ì˜ MCP ì„¤ì • íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    try:
        # parent_dir, _ = os.path.split(os.path.dirname(__file__))
        # config_path = os.path.join(parent_dir, "config", "mcp_config.json")
        current_file_path = os.path.abspath(__file__)
        app_report_dir = os.path.dirname(
            os.path.dirname(os.path.dirname(current_file_path))
        )
        config_path = os.path.join(app_report_dir, "config", "mcp_config.json")
        with open(config_path, "r") as f:
            return json.load(f)
    except Exception as e:
        logger.error(f"ì„¤ì • íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return {}


def create_server_config():
    """MCP ì„œë²„ ì„¤ì •ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    config = load_mcp_config()
    server_config = {}

    if config and "mcpServers" in config:
        for server_name, server_config_data in config["mcpServers"].items():
            # commandê°€ ìˆìœ¼ë©´ stdio ë°©ì‹
            if "command" in server_config_data:
                server_config[server_name] = {
                    "command": server_config_data.get("command"),
                    "args": server_config_data.get("args", []),
                    "transport": "stdio",
                }
            # urlì´ ìˆìœ¼ë©´ sse ë°©ì‹
            elif "url" in server_config_data:
                server_config[server_name] = {
                    "url": server_config_data.get("url"),
                    "transport": "sse",
                }
    if not server_config:
        logger.warning("âš  MCP ì„œë²„ ì„¤ì •ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. MCP ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.")

    return server_config


# --- StateGraph ìƒíƒœ ì •ì˜ ---
class AgentState(TypedDict):
    messages: Annotated[Sequence[BaseMessage], operator.add]

    # --- [í•µì‹¬] ê° ë‹¨ê³„ì˜ ê²°ê³¼ë¬¼ì„ ì €ì¥í•  í•„ë“œ ì¶”ê°€ ---
    connection_summary: str  # 1ë‹¨ê³„: ê´€ê³„ ë¶„ì„ ìš”ì•½ë¬¸
    topic_list: list  # 2ë‹¨ê³„: ì£¼ì œ ë¦¬ìŠ¤íŠ¸
    research_summary: str  # 3ë‹¨ê³„: ë¦¬ì„œì¹˜ ê²°ê³¼
    creative_concept: str  # 4ë‹¨ê³„: ì»¨ì…‰ ê¸°íšì•ˆ
    final_script: dict  # 5ë‹¨ê³„: ìµœì¢… ê¸€ (title, content)


class ReportGenerationPipeline:
    def __init__(self):
        # í´ë˜ìŠ¤ ì´ˆê¸°í™” ì‹œ ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤.
        self.model = qwen_loader_gcp_vllm.get_model()
        self.graph = self._build_graph()

    # ê´€ê³„ ë¶„ì„ ì—ì´ì „íŠ¸
    async def connection_finder_node(self, state: AgentState) -> dict:
        logger.info("--- [Node] Connection Finder ì‹¤í–‰ ---")
        user_input = state["messages"][0].content
        system_prompt = """
            ë‹¹ì‹ ì€ ê³ ë„ë¡œ í›ˆë ¨ëœ 'ê´€ê³„ ë¶„ì„ ì „ë¬¸ê°€'ì…ë‹ˆë‹¤.

            ë‹¹ì‹ ì˜ ìœ ì¼í•œ ì„ë¬´ëŠ” ì…ë ¥ìœ¼ë¡œ ì£¼ì–´ì§„ ë‘ ì‚¬ìš©ìì˜ í”„ë¡œí•„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ë‘ ì‚¬ëŒì˜ **ê³µí†µì **ê³¼ **ìƒí˜¸ë³´ì™„ì ì¸ íŠ¹ì§•**ì„ ì°¾ì•„ë‚´ì–´ í•œ ë¬¸ë‹¨ì˜ ê°„ê²°í•œ í…ìŠ¤íŠ¸ë¡œ ìš”ì•½í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

            **ê·œì¹™:**
            - ì ˆëŒ€ ì…ë ¥ëœ í”„ë¡œí•„ ì •ë³´ ì™¸ì˜ ë‚´ìš©ì„ ì¶”ì¸¡í•˜ê±°ë‚˜ ë§Œë“¤ì–´ë‚´ì§€ ë§ˆì‹­ì‹œì˜¤.
            - ë¶„ì„ ê²°ê³¼ëŠ” ë‹¤ìŒ ì „ë¬¸ê°€ê°€ ì‰½ê²Œ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ì„œìˆ í˜• ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤.
            - ë‹¤ë¥¸ ì¸ì‚¬ë‚˜ ë¶€ê°€ ì„¤ëª… ì—†ì´, ë¶„ì„ ìš”ì•½ë¬¸ë§Œ ì¦‰ì‹œ ì¶œë ¥í•˜ì‹­ì‹œì˜¤.
        """
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_input},
        ]

        response = await self.model.ainvoke(messages)
        return {"connection_summary": response.content}

    async def topic_planner_node(self, state: AgentState) -> dict:
        logger.info("--- [Node] Topic Planner ì‹¤í–‰ ---")
        connection_summary = state["connection_summary"]
        system_prompt = """
                ë‹¹ì‹ ì€ ì°½ì˜ì ì¸ 'ì½˜í…ì¸  ê¸°íšì'ì…ë‹ˆë‹¤.

                ë‹¹ì‹ ì˜ ì„ë¬´ëŠ” ì´ì „ ë‹¨ê³„ì—ì„œ ì „ë‹¬ë°›ì€ 'ê´€ê³„ ë¶„ì„ ìš”ì•½ë¬¸'ì„ ì½ê³ , ê·¸ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ í¥ë¯¸ë¡œìš´ ì½˜í…ì¸  ì£¼ì œ 3ê°œë¥¼ ì œì•ˆí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

                **ê·œì¹™:**
                - ì œì•ˆí•˜ëŠ” ì£¼ì œëŠ” ë°˜ë“œì‹œ ë¶„ì„ëœ ë‚´ìš©(ê³µí†µì , íŠ¹ì§•)ê³¼ ê´€ë ¨ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
                - ì¶œë ¥ì€ **ë°˜ë“œì‹œ** ì•„ë˜ì™€ ê°™ì€ Python ë¦¬ìŠ¤íŠ¸ í˜•ì‹ì˜ ë¬¸ìì—´ì´ì–´ì•¼ í•©ë‹ˆë‹¤.
                - ì˜ˆì‹œ í˜•ì‹: `['ë‘ ì‚¬ëŒì˜ MBTI ê¶í•© íŒŒí—¤ì¹˜ê¸°', 'ê³µí†µ ê´€ì‹¬ì‚¬ì¸ ì˜í™” ì·¨í–¥ìœ¼ë¡œ ë³¸ ë°ì´íŠ¸ ì½”ìŠ¤', 'ì„œë¡œ ë‹¤ë¥¸ ì…ë§›ì„ ëª¨ë‘ ë§Œì¡±ì‹œí‚¬ ë§›ì§‘ íƒë°© ì½”ìŠ¤']`
                - ë‹¤ë¥¸ ì–´ë–¤ í…ìŠ¤íŠ¸ë„ ì¶”ê°€í•˜ì§€ ë§ê³ , ì˜¤ì§ Python ë¦¬ìŠ¤íŠ¸ í˜•ì‹ì˜ ë¬¸ìì—´ë§Œ ì¶œë ¥í•˜ì‹­ì‹œì˜¤.
            """
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": connection_summary},
        ]

        response = await self.model.ainvoke(messages)
        # ì‘ì€ ëª¨ë¸ì€ í˜•ì‹ì„ ì˜ ëª» ì§€í‚¬ ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ì‘ë‹µì—ì„œ ë¦¬ìŠ¤íŠ¸ ë¶€ë¶„ë§Œ ì¶”ì¶œí•˜ëŠ” ë¡œì§ ì¶”ê°€
        content = response.content
        try:
            # ì‘ë‹µ ì•ˆì— ìˆëŠ” ë¦¬ìŠ¤íŠ¸ ë¬¸ìì—´ì„ ì°¾ìŠµë‹ˆë‹¤.
            list_str = content[content.find("[") : content.rfind("]") + 1]
            topic_list = json.loads(list_str.replace("'", '"'))
        except (ValueError, json.JSONDecodeError):
            logger.error(
                f"Topic Plannerê°€ ë¦¬ìŠ¤íŠ¸ í˜•ì‹ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì‘ë‹µ: {content}"
            )
            topic_list = ["ëª¨ë¸ì´ ì£¼ì œ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."]  # ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’

        return {"topic_list": topic_list}

    # --- [í•µì‹¬] researcher_agentë¥¼ ëŒ€ì²´í•  ìƒˆë¡œìš´ ë…¸ë“œ í•¨ìˆ˜ ---
    async def researcher_node(self, state: AgentState) -> dict:
        logger.info("--- [Node] Researcher ì‹¤í–‰ ---")
        topics = state["topic_list"]

        server_config = create_server_config()
        client = MultiServerMCPClient(server_config)
        try:
            tools = await client.get_tools()
            logger.debug("MCP íˆ´ ê°œìˆ˜: ", len(tools))
        except Exception as e:
            logger.warning(f"[INFO] MCP ë„êµ¬ ë¡œë“œ ì‹¤íŒ¨ ë˜ëŠ” ì´ˆê¸°í™” ì•ˆë¨: {e}")
            tools = []

        prompt = hub.pull("hwchase17/structured-chat-agent")
        agent_runnable = create_structured_chat_agent(self.model, tools, prompt)
        executor = AgentExecutor(
            agent=agent_runnable, tools=tools, handle_parsing_errors=True, verbose=True
        )

        # system_prompt="""
        #     ë‹¹ì‹ ì€ ì˜¤ì§ 'tavily_web_search' ë„êµ¬ë§Œ ì‚¬ìš©í•˜ëŠ” 'ìµœì‹  íŠ¸ë Œë“œ ë¦¬ì„œì²˜'ì…ë‹ˆë‹¤.
        #     **ëª¨ë“  ì¶œë ¥ì€ ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤.**

        #     ë‹¹ì‹ ì˜ ì„ë¬´ëŠ” ì´ì „ ë‹¨ê³„ì—ì„œ ë°›ì€ ê° ì£¼ì œì— ëŒ€í•´, **ë°˜ë“œì‹œ `tavily_web_search` ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬** ì›¹ì—ì„œ ìµœì‹  ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ê³  ìš”ì•½í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

        #     **ì ˆëŒ€ ê·œì¹™:**
        #     1.  **ì ˆëŒ€ ë‹¹ì‹ ì˜ ë‚´ë¶€ ì§€ì‹ì´ë‚˜ ì˜ê²¬ìœ¼ë¡œ ë‹µë³€í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.** ë‹¹ì‹ ì€ ì°½ì‘ê°€ê°€ ì•„ë‹ˆë¼ ê²€ìƒ‰ê¸°ì…ë‹ˆë‹¤.
        #     2.  ì…ë ¥ë°›ì€ ì£¼ì œ ë¦¬ìŠ¤íŠ¸ì˜ ê° í•­ëª©ì— ëŒ€í•´ **í•˜ë‚˜ì”©, ê°œë³„ì ìœ¼ë¡œ** `tavily_web_search` ë„êµ¬ë¥¼ í˜¸ì¶œí•´ì•¼ í•©ë‹ˆë‹¤.
        #     3.  ë„êµ¬ í˜¸ì¶œ í›„ ë°›ì€ ê²€ìƒ‰ ê²°ê³¼ë¥¼, ë‹¤ìŒ ì‘ê°€ê°€ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ **ì¶œì²˜(URL)ì™€ í•¨ê»˜ í•µì‹¬ ë‚´ìš©ë§Œ** ê°„ê²°í•œ ë¶ˆë › í¬ì¸íŠ¸(`-`)ë¡œ ìš”ì•½í•˜ì—¬ ì •ë¦¬í•˜ì‹­ì‹œì˜¤.
        # """

        all_results = []
        for topic in topics:
            logger.info(f"'{topic}'ì— ëŒ€í•œ ê²€ìƒ‰ì„ ì‹œì‘í•©ë‹ˆë‹¤...")

            # messages = [
            #     {"role": "system", "content": system_prompt},
            #     {"role": "user", "content": topic},
            # ]

            input_prompt = f"ë‹¤ìŒ ì£¼ì œì— ëŒ€í•´ ì›¹ì—ì„œ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ê³ , ê·¸ ê²°ê³¼ë¥¼ í•œêµ­ì–´ë¡œ ìƒì„¸íˆ ìš”ì•½í•´ì¤˜: '{topic}'"

            try:
                response = await executor.ainvoke({"input": input_prompt})
                topic_result = response.get(
                    "output", f"'{topic}'ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."
                )
                all_results.append(f"- ì£¼ì œ '{topic}' ê²€ìƒ‰ ê²°ê³¼:\n{topic_result}")
            except Exception as e:
                error_msg = f"'{topic}' ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"
                logger.error(error_msg)
                all_results.append(f"- ì£¼ì œ '{topic}' ê²€ìƒ‰ ì‹¤íŒ¨:\n{error_msg}")

        # 7. ê²°ê³¼ë¥¼ LangGraph ìƒíƒœì— ë§ê²Œ í¬ë§·íŒ…í•©ë‹ˆë‹¤.
        research_summary = "\n\n".join(all_results)
        return {"research_summary": research_summary}

    async def creative_concept_node(self, state: AgentState) -> dict:
        logger.info("--- [Node] Creative Concept ì‹¤í–‰ ---")
        # ëª¨ë“  ì´ì „ ê²°ê³¼ë¬¼ì„ ì¡°í•©í•˜ì—¬ í”„ë¡¬í”„íŠ¸ë¥¼ ë§Œë“­ë‹ˆë‹¤.
        prompt_input = f"""
        [ê´€ê³„ ë¶„ì„]: {state['connection_summary']}
        [ê¸°íš ì£¼ì œ]: {state['topic_list']}
        [ë¦¬ì„œì¹˜ ê²°ê³¼]: {state['research_summary']}
        
        ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ 'ì½˜í…ì¸  ê¸°íšì•ˆ'ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.
        """
        system_prompt = """
                ë‹¹ì‹ ì€ íŠ¸ë Œë“œì— ë¯¼ê°í•œ 'í¬ë¦¬ì—ì´í‹°ë¸Œ ë””ë ‰í„°'ì´ì ì¬ì¹˜ ìˆëŠ” 'ì¹´í”¼ë¼ì´í„°'ì…ë‹ˆë‹¤.

                ë‹¹ì‹ ì˜ ì„ë¬´ëŠ” ì‹¤ì œ ì¥ë¬¸ì˜ ê¸€ì„ ì“°ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, ì…ë ¥ëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… ì½˜í…ì¸ ì˜ **í•µì‹¬ ë¼ˆëŒ€ê°€ ë  'ì½˜í…ì¸  ê¸°íšì•ˆ'**ì„ ë§Œë“œëŠ” ê²ƒì…ë‹ˆë‹¤.

                **ì…ë ¥ ì •ë³´:**
                - ê´€ê³„ ë¶„ì„ ìš”ì•½
                - ì½˜í…ì¸  ì£¼ì œ ë¦¬ìŠ¤íŠ¸
                - ê´€ë ¨ ê²€ìƒ‰ ê²°ê³¼

                **ê¸°íšì•ˆ ì‘ì„± ê°€ì´ë“œ:**
                1.  **ì»¨ì…‰ ê²°ì •:** ì œê³µëœ ì •ë³´ë¥¼ ë³´ê³ , ì „ì²´ ì½˜í…ì¸ ë¥¼ ì–´ë–¤ ëŠë‚Œìœ¼ë¡œ ë§Œë“¤ì§€ ê²°ì •í•˜ì„¸ìš”. (ì˜ˆ: SNS ë°ˆ ìŠ¤íƒ€ì¼, ì»¤ë®¤ë‹ˆí‹° í­ë¡œ ê¸€, ì§§ì€ ì‹œíŠ¸ì½¤ ì‹œë‚˜ë¦¬ì˜¤, ì§„ì§€í•œ ë¶„ì„ ë¦¬í¬íŠ¸ ë“±) **ë‰´ìŠ¤ í˜•ì‹ì— ì–½ë§¤ì¼ í•„ìš” ì „í˜€ ì—†ìŠµë‹ˆë‹¤.**
                2.  **í—¤ë“œë¼ì¸ ì œì•ˆ:** ê²°ì •ëœ ì»¨ì…‰ì— ë§ëŠ”, ì‚¬ëŒë“¤ì˜ ì‹œì„ ì„ í™• ë„ëŠ” í—¤ë“œë¼ì¸ ì•„ì´ë””ì–´ë¥¼ 1~2ê°œ ì œì•ˆí•˜ì„¸ìš”.
                3.  **ì„¹ì…˜ë³„ í•µì‹¬ ë©”ì‹œì§€ ì„¤ê³„:** ê¸€ì˜ ê° ë¶€ë¶„ì— ì–´ë–¤ ë‚´ìš©ì´ ë“¤ì–´ê°ˆì§€, í•µì‹¬ í‚¤ì›Œë“œë‚˜ ì§§ì€ ë¬¸ì¥(ì•µì»¤ í…ìŠ¤íŠ¸)ìœ¼ë¡œ ì„¤ê³„í•´ì£¼ì„¸ìš”. ì´ëª¨ì§€ë¥¼ í™œìš©í•˜ì—¬ í†¤ì•¤ë§¤ë„ˆë¥¼ í‘œí˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

                **ê·œì¹™:**
                - ì ˆëŒ€ ê¸´ ë¬¸ì¥ìœ¼ë¡œ ë³¸ë¬¸ì„ ì‘ì„±í•˜ì§€ ë§ˆì„¸ìš”. ë‹¹ì‹ ì˜ ì—­í• ì€ ì˜¤ì§ 'ê¸°íš'ì…ë‹ˆë‹¤.
                - ê²°ê³¼ë¬¼ì€ ì•„ë˜ ì˜ˆì‹œì™€ ê°™ì´ êµ¬ì¡°í™”ëœ í…ìŠ¤íŠ¸ í˜•ì‹ì´ì–´ì•¼ í•©ë‹ˆë‹¤.

                ---
                **ê¸°íšì•ˆ ì¶œë ¥ ì˜ˆì‹œ:**

                **ì»¨ì…‰:** ì°ì¹œ ë°”ì´ë¸Œ í­ë°œí•˜ëŠ” SNS ë°ˆ ìŠ¤íƒ€ì¼ ê²Œì‹œë¬¼

                **í—¤ë“œë¼ì¸ ì•„ì´ë””ì–´:**
                - "ğŸš¨[ìš°ì •ê²½ë³´] ESTP x ENFP, ì´ ì¡°í•© ì§€êµ¬ì— ë¬´ìŠ¨ ì§“ì„ í•œê±°ì•¼?!"
                - "ì†ë³´) ëŒ€í™” 424ë²ˆ, ê±”ë„¤ ê·¸ëƒ¥ ì¹œêµ¬ ì•„ë‹ˆë˜"

                **ì„¹ì…˜ë³„ í•µì‹¬ ë©”ì‹œì§€:**
                - **ì˜¤í”„ë‹:** "ì´ê±´ ê·¸ëƒ¥ ì¹œêµ¬ê°€ ì•„ëƒ. ìš°ì£¼ê¸‰ ì‚¬ê±´ì´ë‹¤." ë¼ëŠ” ë¬¸êµ¬ì™€ í•¨ê»˜ ëŒ€í™” íšŸìˆ˜ ê°•ì¡°. ë¹…ë±… ì´ëª¨ì§€ ğŸ’¥ ì‚¬ìš©.
                - **MBTI ì¼€ë¯¸:** "ë¡¤ëŸ¬ì½”ìŠ¤í„°", "ì‚¬ê±´ ì œì¡°ê¸°" í‚¤ì›Œë“œë¡œ ë‘˜ì˜ ì‹œë„ˆì§€ í‘œí˜„. í‘œ(í…Œì´ë¸”) í˜•ì‹ìœ¼ë¡œ íŠ¹ì§• ë¹„êµ.
                - **ì·¨ë¯¸ ë¶„ì„:** "ì·¨ë¯¸ë„ ì–´ë”˜ê°€ ì •ìƒ ì•„ë‹˜" ì´ë¼ëŠ” ì†Œì œëª©. ê° ì·¨ë¯¸ë¥¼ í•œ ì¤„ ë°ˆìœ¼ë¡œ ìš”ì•½. (ì˜ˆ: ë¸ŒëŸ°ì¹˜? -> ë‹¨ìˆœ ì‹ì‚¬ ì•„ë‹˜, ì˜ˆìˆ ì„)
                - **ë¯¸ë˜ ì˜ˆì¸¡:** "ì´ ìš°ì •, ë„·í”Œë¦­ìŠ¤ ì…ì¥í•˜ì„¸ìš”" ë¼ëŠ” ì»¨ì…‰ìœ¼ë¡œ ê°€ìƒ ë“œë¼ë§ˆ ì •ë³´ ìƒì„±.
                - **ë§ˆë¬´ë¦¬:** "ì¿ í‚¤ ì˜ìƒ ìˆìŒ" ì´ë¼ëŠ” ì†Œì œëª©ìœ¼ë¡œ ë‹¤ìŒ ë§Œë‚¨ì— ëŒ€í•œ ê¸°ëŒ€ê° ì¦í­. #ë„íŒŒë¯¼_ëŒ€í­ë°œ ê°™ì€ í•´ì‹œíƒœê·¸ ì‚¬ìš©.
                ---

                ì´ì œ, ì£¼ì–´ì§„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìœ„ ê°€ì´ë“œì— ë§ì¶° ì°½ì˜ì ì¸ 'ì½˜í…ì¸  ê¸°íšì•ˆ'ì„ ì‘ì„±í•˜ì„¸ìš”.
            """
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": prompt_input},
        ]
        # creative_concept_promptë¥¼ ì‚¬ìš©í•˜ì—¬ LLM í˜¸ì¶œ
        response = await self.model.ainvoke(messages)
        return {"creative_concept": response.content}

    # ì»¨í…ì¸  ìƒì„± ì—ì´ì „íŠ¸
    async def content_generator_node(self, state: AgentState) -> dict:
        logger.info("--- [Node] Content Generator ì‹¤í–‰ ---")
        # creative_concept ê²°ê³¼ë¥¼ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©
        creative_concept = state["creative_concept"]
        system_prompt = """
                ë‹¹ì‹ ì€ ë›°ì–´ë‚œ í•„ë ¥ì„ ê°€ì§„ 'ì½˜í…ì¸  ì‘ê°€'ì…ë‹ˆë‹¤.
                **ëª¨ë“  ì¶œë ¥ì€ ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤.**

                ë‹¹ì‹ ì˜ ìœ ì¼í•œ ì„ë¬´ëŠ”, ì´ì „ ë‹¨ê³„ì˜ í¬ë¦¬ì—ì´í‹°ë¸Œ ë””ë ‰í„°ê°€ ì‘ì„±í•œ **'ì½˜í…ì¸  ê¸°íšì•ˆ'ì„ ì…ë ¥ìœ¼ë¡œ ë°›ì•„, ê·¸ ë¼ˆëŒ€ì— ì‚´ì„ ë¶™ì—¬ ì¬ë¯¸ìˆê³  ì™„ì„±ë„ ë†’ì€ ìµœì¢… ê¸€ì„ ì‘ì„±**í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

                **ë§¤ìš° ì¤‘ìš”í•œ ê·œì¹™:**
                - **ì ˆëŒ€** 'ì½˜í…ì¸  ê¸°íšì•ˆ'ì„ ê·¸ëŒ€ë¡œ ë³µì‚¬í•´ì„œëŠ” ì•ˆ ë©ë‹ˆë‹¤.
                - ê¸°íšì•ˆì— ì œì‹œëœ **ì»¨ì…‰, í†¤ì•¤ë§¤ë„ˆ, í—¤ë“œë¼ì¸, ì„¹ì…˜ë³„ í•µì‹¬ ë©”ì‹œì§€**ë¥¼ ì¶©ì‹¤íˆ ë”°ë¥´ë©´ì„œ, ê° ì„¹ì…˜ì„ **ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ê³¼ í’ë¶€í•œ ë¬˜ì‚¬ê°€ ë‹´ê¸´ ì™„ì „í•œ ë¬¸ë‹¨**ìœ¼ë¡œ ë§Œë“¤ì–´ì•¼ í•©ë‹ˆë‹¤.
                - ë‹¹ì‹ ì˜ ëª©í‘œëŠ” ë¼ˆëŒ€(ê¸°íšì•ˆ)ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë©‹ì§„ ìµœì¢… ê¸€ì„ **ì°½ì¡°**í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ì´ì œ ì£¼ì–´ì§„ 'ì½˜í…ì¸  ê¸°íšì•ˆ'ì„ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… ê¸€ì„ ì‘ì„±í•˜ì„¸ìš”.
            """
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": creative_concept},
        ]

        # ... LLM í˜¸ì¶œ ...
        response = await self.model.ainvoke(messages)
        final_script = safe_json_parse(response.content)
        logger.info(f"Generated Script Title: {final_script.get('title')}")
        return {"final_script": final_script}

    # ê²€ìˆ˜ ë° í¸ì§‘ ì—ì´ì „íŠ¸
    async def editor_node(self, state: AgentState) -> dict:
        """
        content_generatorê°€ ìƒì„±í•œ ê¸€ì„ ìµœì¢…ì ìœ¼ë¡œ ê²€ìˆ˜í•˜ê³ ,
        ì™„ë²½í•œ JSON í˜•ì‹ìœ¼ë¡œ í¬ë§·íŒ…í•˜ëŠ” ìµœì¢… ê´€ë¬¸ ì—­í• .
        """
        logger.info("--- [Node 6] Editor (Final QA) ì‹¤í–‰ ---")

        # 1. ì´ì „ ë‹¨ê³„ì—ì„œ ìƒì„±ëœ 'final_script' ë”•ì…”ë„ˆë¦¬ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
        #    ì´ë•Œ get()ì„ ì‚¬ìš©í•˜ì—¬, ë§Œì•½ í‚¤ê°€ ì—†ì–´ë„ ì—ëŸ¬ê°€ ë‚˜ì§€ ì•Šë„ë¡ í•©ë‹ˆë‹¤.
        script_dict = state.get("final_script", {})

        # 2. content_generatorê°€ JSON íŒŒì‹±ì— ì‹¤íŒ¨í•˜ì—¬ ë¹ˆ dictë¥¼ ì „ë‹¬í–ˆì„ ê²½ìš°ì— ëŒ€ë¹„.
        if (
            not script_dict
            or not script_dict.get("title")
            or not script_dict.get("content")
        ):
            error_content = (
                "ì½˜í…ì¸  ìƒì„± ë‹¨ê³„ì—ì„œ ìœ íš¨í•œ ì œëª©ê³¼ ë³¸ë¬¸ì„ ë§Œë“¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
            )
            logger.error(error_content)
            # ìµœì¢… ì¶œë ¥ë„ JSON í˜•ì‹ì„ ìœ ì§€í•´ì£¼ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.
            final_json_str = json.dumps(
                {"title": "ìƒì„± ì˜¤ë¥˜", "content": error_content},
                ensure_ascii=False,
                indent=2,
            )
            return {
                "messages": [AIMessage(content=final_json_str, name="editor_assistant")]
            }

        # 3. LLMì—ê²Œ ìµœì¢… í¬ë§·íŒ…ì„ ì§€ì‹œí•˜ëŠ” í”„ë¡¬í”„íŠ¸ë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤.
        #    ì´ì „ ë‹¨ê³„ì˜ ê²°ê³¼(ë”•ì…”ë„ˆë¦¬)ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ ì „ë‹¬í•©ë‹ˆë‹¤.
        input_text = (
            f"ì œëª©: {script_dict.get('title')}\n\në³¸ë¬¸:\n{script_dict.get('content')}"
        )

        system_prompt = """
        [ ì—­í•  ] ë‹¹ì‹ ì€ ì¶œíŒì‚¬ì˜ ìµœì¢… í¸ì§‘ì(Editor)ì´ì, ë§¤ìš° ì—„ê²©í•œ 'ë°ì´í„° í¬ë§·í„°'ì…ë‹ˆë‹¤.
        [ ì§€ì‹œ ] ëª¨ë“  ë‹µë³€ì€ ë°˜ë“œì‹œ, ê·¸ë¦¬ê³  ì˜¤ì§ í•œêµ­ì–´ë¡œë§Œ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤.

        ë‹¹ì‹ ì˜ ìœ ì¼í•œ ì„ë¬´ëŠ” ì…ë ¥ìœ¼ë¡œ ë°›ì€ 'ì œëª©'ê³¼ 'ë³¸ë¬¸' í…ìŠ¤íŠ¸ë¥¼ **ë‹¨ í•˜ë‚˜ì˜, ë‹¤ë¥¸ ì–´ë–¤ ì„¤ëª…ë„ ì—†ëŠ”, ì™„ë²½í•œ JSON ê°ì²´**ë¡œ ë§Œë“œëŠ” ê²ƒì…ë‹ˆë‹¤.

        **ì ˆëŒ€ ê·œì¹™:**
        1.  ì…ë ¥ í…ìŠ¤íŠ¸ì˜ ë‚´ìš©ì„ ì°½ì˜ì ìœ¼ë¡œ ìˆ˜ì •í•˜ì§€ ë§ˆì‹­ì‹œì˜¤. ì˜¤íƒˆìë‚˜ ë¬¸ë²• êµì •ì€ ê°€ëŠ¥í•©ë‹ˆë‹¤.
        2.  ë‹¹ì‹ ì˜ ìµœì¢… ì¶œë ¥ë¬¼ì€ **ì˜¤ì§ JSON ê°ì²´ í•˜ë‚˜**ì—¬ì•¼ í•©ë‹ˆë‹¤. "ë‹¤ìŒì€ JSONì…ë‹ˆë‹¤" ì™€ ê°™ì€ ì„¤ëª…, ì¸ì‚¬, ì½”ë“œ ë¸”ë¡ ë§ˆí¬ë‹¤ìš´(```) ë“± **JSON ì™¸ì˜ ë¬¸ìëŠ” ë‹¨ í•˜ë‚˜ë„ í¬í•¨í•´ì„œëŠ” ì•ˆ ë©ë‹ˆë‹¤.**
        3.  ìµœì¢… ì¶œë ¥ í˜•ì‹: `{"title": "ì…ë ¥ë°›ì€ ì œëª©", "content": "ì…ë ¥ë°›ì€ ë³¸ë¬¸ ë‚´ìš©"}`
        4.  ë³¸ë¬¸ ë‚´ìš©(`content`)ì˜ ëª¨ë“  ì¤„ë°”ê¿ˆì€ `\\n`ìœ¼ë¡œ ì´ìŠ¤ì¼€ì´í”„ ì²˜ë¦¬í•´ì•¼ í•©ë‹ˆë‹¤.
        """

        messages = [
            SystemMessage(content=system_prompt),
            HumanMessage(content=input_text),
        ]

        # 4. LLM í˜¸ì¶œ
        response = await self.model.ainvoke(messages)

        # 5. LLMì´ ìƒì„±í•œ ìµœì¢… ê²°ê³¼ë¬¼ì„ messagesì— ë‹´ì•„ ë°˜í™˜í•©ë‹ˆë‹¤.
        #    ì—¬ê¸°ì„œëŠ” LLMì´ ì™„ë²½í•œ JSON ë¬¸ìì—´ì„ ìƒì„±í–ˆë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤.
        #    ë§Œì•½ ì—¬ê¸°ì„œë„ íŒŒì‹± ì—ëŸ¬ê°€ ë°œìƒí•œë‹¤ë©´, ì¶”ê°€ì ì¸ ì˜ˆì™¸ ì²˜ë¦¬ê°€ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        final_json_str = response.content
        logger.info("Editorê°€ ìµœì¢… JSON í¬ë§·íŒ… ì™„ë£Œ.")

        return {
            "messages": [AIMessage(content=final_json_str, name="editor_assistant")]
        }

    def _build_graph(self) -> StateGraph:
        # --- StateGraphë¡œ ê²°ì •ë¡ ì  íŒŒì´í”„ë¼ì¸ êµ¬ì¶• ---
        workflow = StateGraph(AgentState)

        # ê° ë…¸ë“œë¥¼ ê·¸ë˜í”„ì— ì¶”ê°€
        workflow.add_node("connection_finder", self.connection_finder_node)
        workflow.add_node("topic_planner", self.topic_planner_node)
        workflow.add_node("researcher", self.researcher_node)
        workflow.add_node("creative_concept", self.creative_concept_node)
        workflow.add_node("content_generator", self.content_generator_node)
        workflow.add_node("editor", self.editor_node)

        # ì—£ì§€ë¥¼ ìˆœì„œëŒ€ë¡œ ì—°ê²° (ì´ì œ ë¶„ê¸° ë¡œì§ì´ í•„ìš” ì—†ìŒ)
        workflow.add_edge(START, "connection_finder")
        workflow.add_edge("connection_finder", "topic_planner")
        workflow.add_edge("topic_planner", "researcher")
        workflow.add_edge("researcher", "creative_concept")
        workflow.add_edge("creative_concept", "content_generator")
        workflow.add_edge("content_generator", "editor")
        workflow.add_edge("editor", END)

        # ê·¸ë˜í”„ ì»´íŒŒì¼ ë° ì‹¤í–‰
        return workflow.compile()

    async def run(self):
        """íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤."""
        initial_input = {
            "messages": [
                HumanMessage(
                    content="""
                    ë‘ ì‚¬ìš©ìë¥¼ ìœ„í•œ í¥ë¯¸ë¡œìš´ ë§¤ì¹­ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”. ì „ì²´ ì‘ì—…ì€ ìë™ìœ¼ë¡œ ì§„í–‰ë  ê²ƒì…ë‹ˆë‹¤.

                    ---
                    **ì‚¬ìš©ì A í”„ë¡œí•„:**
                    - ì´ë¦„: ê¹€ì§€í›ˆ, MBTI: INTP, ê´€ì‹¬ì‚¬: ìŒì•… ê°ìƒ, ë„·í”Œë¦­ìŠ¤ ë³´ê¸°, ì½”ë”©, ë³´ë“œê²Œì„

                    **ì‚¬ìš©ì B í”„ë¡œí•„:**
                    - ì´ë¦„: ë°•ì„œì—°, MBTI: ENFJ, ê´€ì‹¬ì‚¬: ìŒì•… ê°ìƒ, ë§›ì§‘ íƒë°©, ë´‰ì‚¬í™œë™
                    ---
                    """
                )
            ]
        }
        final_node_output = None
        async for chunk in self.graph.astream(initial_input):
            logger.debug(f"--- ìŠ¤íŠ¸ë¦¬ë° ì²­í¬ ---\n{chunk}")
            if END in chunk:
                final_node_output = chunk[END]

        logger.info("\n\n=============== ìµœì¢… ê²°ê³¼ë¬¼ ===============")
        if final_node_output:
            final_message_content = final_node_output["messages"][-1].content
            logger.info(f"ìµœì¢… ìƒì„±ëœ ì½˜í…ì¸ :\n{final_message_content}")
        else:
            logger.error(
                "ìµœì¢… ê²°ê³¼ë¬¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ê·¸ë˜í”„ê°€ ì •ìƒ ì¢…ë£Œë˜ì§€ ì•ŠìŒ)"
            )


if __name__ == "__main__":
    pipeline = ReportGenerationPipeline()
    asyncio.run(pipeline.run())
